{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMDxA/QBruzTrQtEHc1ic6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GugulothBhuvan/stock_price_prediction_using_LSMT/blob/main/stockMarketprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stock Market Prediction and Forecasting Using Stacked LSTM"
      ],
      "metadata": {
        "id": "s2XsAuKt9Xtl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY-XVMw69TFS"
      },
      "outputs": [],
      "source": [
        "### Keras and Tensorflow >2.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Collection\n",
        "import pandas_datareader as pdr\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2R-FBbl49iJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = \"2368030b29f2b8dc5a0053defb09dda587aba60b\""
      ],
      "metadata": {
        "id": "f7XaMbPeAC8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pdr.get_data_tiingo('AAPL', api_key=key)\n",
        "df.to_csv('AAPL.csv')"
      ],
      "metadata": {
        "id": "Wc4zLId79ovQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "G6RQ5Bl99xrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "994gTs77AUQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "v4Q2XR6aBBQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df.reset_index()['close']"
      ],
      "metadata": {
        "id": "YbAFxaxuAjwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "k9Z_f2FdAwCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "1nHg90IvBeYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df1)"
      ],
      "metadata": {
        "id": "Rb7_Ml9ZBhs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM are sensitive to the scale of the data,so we are applying MinMax scaler"
      ],
      "metadata": {
        "id": "ZSrGrDErB_fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "W4Sk3IzxBuKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
      ],
      "metadata": {
        "id": "OnuHeX49CNU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "2m54yJRpCjmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##splitting dataset into train and test split\n",
        "training_size=int(len(df1)*0.65)\n",
        "test_size=len(df1)-training_size\n",
        "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
      ],
      "metadata": {
        "id": "rf9LQZ4mClww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_size,test_size"
      ],
      "metadata": {
        "id": "9ep6p9_wEetA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "rUTTCN8-Ej8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "# Define the function to create dataset matrix\n",
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-time_step-1):\n",
        "        a = dataset[i:(i+time_step), 0]   # Extract input sequence\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + time_step, 0])  # Extract corresponding output value\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# Assuming you have your training and testing datasets defined as train_data and test_data\n",
        "# Reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
        "time_step = 100\n",
        "X_train, Y_train = create_dataset(train_data, time_step)\n",
        "X_test, Y_test = create_dataset(test_data, time_step)\n"
      ],
      "metadata": {
        "id": "zddbRZGEDNrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape), print(Y_train.shape)"
      ],
      "metadata": {
        "id": "eCLOJnRvE6nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape), print(Y_test.shape)"
      ],
      "metadata": {
        "id": "Kl8S2ZGfFe2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
      ],
      "metadata": {
        "id": "urJxChtVFhTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create the Stacked LSTM model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "metadata": {
        "id": "MmGntv4yFvD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')"
      ],
      "metadata": {
        "id": "4Lgjm1RnFxOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "xVaJzgYaF0oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nlT1NRQmF2qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=100,batch_size=64,verbose=1)"
      ],
      "metadata": {
        "id": "xJQCe0bNF7pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "h2-41svCF_Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "RtGAgS4JGMEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Lets Do the prediction and check performance metrics\n",
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)"
      ],
      "metadata": {
        "id": "0s_b868lGQmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Transformback to original form\n",
        "train_predict=scaler.inverse_transform(train_predict)\n",
        "test_predict=scaler.inverse_transform(test_predict)"
      ],
      "metadata": {
        "id": "Ko4wEQpmGTOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Calculate RMSE performance metrics\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "math.sqrt(mean_squared_error(y_train,train_predict))"
      ],
      "metadata": {
        "id": "Np3NFdUKGVOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Test Data RMSE\n",
        "math.sqrt(mean_squared_error(Y_test,test_predict))"
      ],
      "metadata": {
        "id": "C91p3NG1GZbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Plotting\n",
        "# shift train predictions for plotting\n",
        "look_back=100\n",
        "trainPredictPlot = numpy.empty_like(df1)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(df1)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(df1))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IzaGLPL1GbVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "id": "rHviLzX5GdcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_input=test_data[341:].reshape(1,-1)\n",
        "x_input.shape"
      ],
      "metadata": {
        "id": "m9ZF7Yp5GfF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()"
      ],
      "metadata": {
        "id": "73lwA2IuGnXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_input"
      ],
      "metadata": {
        "id": "KYVPrMHaGohU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate prediction for next 10 days\n",
        "from numpy import array\n",
        "\n",
        "lst_output=[]\n",
        "n_steps=100\n",
        "i=0\n",
        "while(i<30):\n",
        "\n",
        "    if(len(temp_input)>100):\n",
        "        #print(temp_input)\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        #print(x_input)\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        #print(temp_input)\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        print(len(temp_input))\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "\n",
        "\n",
        "print(lst_output)"
      ],
      "metadata": {
        "id": "cRXW79zqGrb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_new = np.arange(1158, 1158 + len(df1[1158:]))\n",
        "day_pred = np.arange(1158 + len(df1[1158:]), 1158 + len(df1[1158:]) + len(lst_output))\n"
      ],
      "metadata": {
        "id": "7h2EdN2bG7um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "v4NwkJkdG8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df1)"
      ],
      "metadata": {
        "id": "dYk0lG8CG-ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(day_new,scaler.inverse_transform(df1[1158:]))\n",
        "plt.plot(day_pred,scaler.inverse_transform(lst_output))"
      ],
      "metadata": {
        "id": "c1jMbQv8HAMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df1.tolist()\n",
        "df3.extend(lst_output)\n",
        "plt.plot(df3[1200:])"
      ],
      "metadata": {
        "id": "FCsAoDmVHDlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=scaler.inverse_transform(df3).tolist()\n",
        "plt.plot(df3)"
      ],
      "metadata": {
        "id": "ba9jw9VnJ4ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7nhLg9VJ89e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}